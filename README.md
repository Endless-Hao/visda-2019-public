

## VisDA2019: 3rd Visual Domain Adaptation Challenge

Hi!

This is the development kit repository for the [2019 Visual Domain Adaptation (VisDA) Challenge](http://ai.bu.edu/visda-2019/). Here you can find details on how to download datasets, run baseline models and evaluate the perfomance of your model. The evaluation can be performed both locally and remotely on the CodaLab evaluation server. Please see the main website for competition details, rules and dates.

You can find the development kits for the two competition tracks by following these links:
- [multi-source domain adaptation](multisource)
- [semi-supervised domain adaptation](semisupervised) 


If you consider using data, code or its derivatives, please consider citing:

```
@article{peng2018moment,
  title={Moment Matching for Multi-Source Domain Adaptation},
  author={Peng, Xingchao and Bai, Qinxun and Xia, Xide and Huang, Zijun and Saenko, Kate and Wang, Bo},
  journal={arXiv preprint arXiv:1812.01754},
  year={2018}
}

```

If you find any bugs please [open an issue](https://github.com/VisionLearningGroup/visda-2019-public/issues).

Have fun!
